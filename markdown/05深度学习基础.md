# 人工智能

## 第二阶段

### （四）深度学习

- 概念

	- 深度学习是机器学习的子领域，深度学习的概念源于人工神经网络的研究，含多个隐藏层的多层感知机就是一种深度学习结构。
	- 深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。
	- 研究深度学习的动机在于建立模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本等。
	- 区别于传统的浅层学习，深度学习的不同在于：

		- 1)强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；
		- 2)明确了特征学习的重要性。通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更容易。

- 研发模型完整流程

	- 1.数据处理(采集、标注、清洗、增强、格式转化、预处理等)
	- 2.模型研发(设计、优化、训练)
	- 3.测试评估
	- 4.模型部署

- 神经网络

	- 相关概念

		- 感知机

		- 神经网络

			- 把大量的神经元有机的组合在一起构成一神经网络。
			- 神经网络结构包括：输入层、隐藏层、输出层。

		- 梯度弥散、梯度爆炸

			- 当神经网络模型过深时，在残差反向传播（使用链式求导法则求梯度）的过程中，易出现梯度弥散(又叫梯度消失)和梯度爆炸。特别地，使用sigmoid激活函数时，很容易会出现梯度消失的现象。

		- 激活函数

			- 作用

				- 1.主要作用是给网络提供非线性能力。
				- 2.另一个重要作用是执行数据的归一化，将数据映射到某个范围内，再继续向下传递。
				- 3.输出层的激活函数还有其他的用途

					- 恒等函数

							- 用于解决回归问题

					- sigmoid

							- 结果表示属于正类的概率

								- 用于解决二分类问题

					- softmax

							- 结果表述属于其中某一类i的概率，属于所有类的概率之和为1

								- 用于解决多分类问题

	- PyTorch搭建神经网络相关API

		- 数据集

			- 自定义数据集

				- 继承torch.utils.data.Dataset，实现__len__()和__getitem__()函数

			- 读取数据集

				- torch.utils.data.DataLoader

					- DataLoader(self, dataset, batch_size=1, shuffle=False, sampler=None,
                batch_sampler=None, num_workers=0, collate_fn=None,
                pin_memory=False, drop_last=False, timeout=0,
                worker_init_fn=None, multiprocessing_context=None)
    参数：
    dataset：加载的数据集(Dataset对象)
    batch_size：batch size
    shuffle:：是否将数据打乱
    sampler： 样本抽样
    num_workers：使用多进程加载的进程数，0代表不使用多进程
    collate_fn： 如何将多个样本数据拼接成一个batch，一般使用默认的拼接方式即可
    pin_memory：是否将数据保存在pin memory区，pin memory中的数据转到GPU会快一些
    drop_last：dataset中的数据个数可能不是batch_size的整数倍，drop_last为True会将多出来不足一个batch的数据丢弃

		- 创建神经网络模型

			- 继承torch.nn.Module，实现__init__()和__forward__()函数
			- 模型参数初始化

				- 高斯分布(均值0方差1)初始化

					- 缺点：随着神经网络深度的加深，这个方法不能解决梯度消失的问题。

				- Xavier初始化

					- Xavier Glorot提出一个洞见：
    激活值的方差是逐层递减的，这导致反向传播中的梯度也逐层递减。要解决梯度消失，
    就要避免激活值方差的衰减，最理想的情况是，每层的输出值（激活值）保持高斯分布。
					- 定义

						- bias初始化为0，w高斯初始化后再乘以一个rescale系数(sqrt(1/n), n是输入参数的个数(即输入特征数)。
						- 即当参数w的标准差为sqrt(1/n)时，var(y)=var(x)，方差不衰减。

					- 优点：参数经过Xavier初始化后，linear层的输出值的分布没有大的变化，依旧接近高斯分布。
					- 缺点：Xavier只适用于线性激活函数。如果我们添加relu激活函数，激活值的分布就开始跑偏了。
但实际上，对于深层神经网络来说，线性激活函数是没有价值的，神经网络需要使用非线性激活函数来构建复杂的非线性系统。

				- kaiming初始化

					- 今天的神经网络普遍使用relu激活函数。于是kaiming he提出了针对relu的kaiming初始化。
					- 实际上，Kaiming初始化已经被Pytorch用作默认的参数初始化函数。
					- 定义

						- bias初始化为0，w高斯初始化后再乘以一个rescale系数(sqrt(2/n), n是输入参数的个数)。
						- 即当参数w的标准差为sqrt(2/n)时，var(relu(y))=var(x)，经过relu激活后的方差不衰减。

		- 保存和加载模型参数

			- net.state_dict()

				- torch.save(self.net.state_dict(), f"./checkpoint/{epoch}.t")
				- 常用的保存state_dict的格式是".pt"或'.pth'的文件

			- net.load_state_dict()

				- self.net = Netv3()
self.net.load_state_dict(torch.load("checkpoint/2.t"))

		- 使用不同的设备(CPU或GPU)来训练模型

			- 需要将模型model和数据data同时移动到相同设备上(cpu或gpu)。

				- DEVICE = "cuda:0"

# 同时将model和data移动到相同设备上
self.net.to(DEVICE)
img, tag = img.to(DEVICE), tag.to(DEVICE)

			- 定义device设备的两种方式

				- device = "cuda"  # 默认cuda:0
				- device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

			- 移动设备的两种方式

				- 默认情况下，数据创建在主存储器中，然后直接用cpu来计算。
				- 移动到GPU上

					- device = "cuda:0" 或 device = "cuda"
data = data.to(device)
					- data = data.cuda() 或 data = data.cuda(0)

				- 移动到CPU上

					- device = "cpu"
data = data.to(device)
					- data = data.cpu()

		- TensorBoard可视化

			- 首先，电脑上先安装TensorBoard可视化工具: pip install tensorboard
			- 使用torch.utils.tensorboard.SummaryWriter写入要可视化的数据

				- from torch.utils.tensorboard import SummaryWriter

self.summartWriter = SummaryWriter("./logs")
self.summaryWriter.add_scalars("loss", {"train_loss_avg": train_loss_avg, "test_loss_avg": test_loss_avg}, epoch)
self.summaryWriter.add_scalar("score", score, epoch)

			- 最后，使用命令可视化: tensorboard --logdir=文件目录

		- 部署

			- Torch脚本

				- 老版本的PyTorch有一个缺点，PyTorch编写的模型无法在其他高性能环境(如C++)中运行。为了解决这个问题，新版本的PyTorch新增了TorchScript，并且提供了一些工具帮助我们将模型从纯Python程序转换为可独立于Python运行的TorchScript脚本程序。由于Torch脚本程序可独立于Python环境运行，我们可将PyTorch模型转换为TorchScript，然后在其他的语言环境中运行。
				- torch.jit工具

					- 将PyTorch模型转换为TorchScript

						- 将PyTorch模型转换为torch.jit.RecursiveScriptModule

							- torch.jit.script(obj)
        obj: 一个nn.Module模块或function函数，相应返回ScriptModule或ScriptFunction

						- 将PyTorch模型转换为torch.jit.TopLevelTracedModule

							- torch.jit.trace(func, example_inputs)
        func: 个nn.Module模块或function函数，相应返回ScriptModule或ScriptFunction
        example_inputs: 一组示例输入

					- 加载TorchScript模型

						- torch::jit::load（filename）加载到C ++ API中

							- //读取图片
cv::Mat img = cv::imread("image/3.jpg", cv::IMREAD_GRAYSCALE);
//转换为Tensor并reshape为(N, V)的形状
torch::Tensor tensor_img = torch::from_blob(img.data, {1, img.rows * img.cols}, torch::kByte).toType(torch::kFloat);
//归一化
tensor_img /= 255.;

//使用torch.jit工具加载.pt模型文件
auto module = torch::jit::load("jit/mnist_trace_model_v1.pt");

//使用模型
//1.先将tensor_img数据转换为torch.jit.IValue类型
std::vector<torch::jit::IValue> inputs;
inputs.push_back(tensor_img);
//2.使用模型
auto result = module.forward(inputs).toTensor();
std::cout << result << std::endl;
std::cout << torch::argmax(result, 1) << std::endl;

						- torch.jit.load（filename）加载到Python API中

							- torch.jit.load总是首先加载到CPU上，可使用map_location将其移动到其他设备上。
							- load(f, map_location=None)
    f: 文件类对象（必须实现read，readline，tell和seek），或为文件名的字符串
    map_location: 可以是一个字符串（例如，'cpu'，'cuda：0'），一个设备（例如，torch.device（'cpu'））

		- torchvision工具库

			- torchvision是独立于PyTorch的关于图像操作的一些方便工具库。
			- torchvision的几个主要包

				- torchvision.datasets

					- 几个常用视觉数据集，可以下载和加载。

						- MNIST

							- MNIST数据集是入门机器学习/模式识别的最经典数据集之一。
原始数据集可在MNIST官网下载：http://yann.lecun.com/exdb/mnist/

						- COCO（用于图像标注和目标检测）(Captioning and Detection)
						- LSUN Classification
						- ImageFolder
						- Imagenet-12
						- CIFAR10 and CIFAR100
						- STL10

				- torchvision.models

					- 几种流行的模型结构

				- torchvisionn.transforms

					- 常用的图像操作。例如：随机切割，旋转，数据类型转换(图像到tensor、numpy数组到tensor、tensor到图像)等。
					- transforms.ToPILImage()

						- 将Tensor(C x H x W)或numpy.ndarray(H x W x C)转化为PIL Image

					- transforms.ToTensor()

						- 将numpy.ndarray(H x W x C)或PIL Image转化为Tensor(C x H x W)

				- torchvision.utils

					- 用来做雪碧图的(sprite image)。

		- 其他API

			- self.softmax = torch.nn.Softmax(dim=1)

				- 定义Softmax激活函数，dim指明沿着哪个维度。

			- torch.sum(a, dim=1, keepdim=True)

				- keepdim=True保持维度

			- torch.argmax(input, dim, keepdim)

				- 获取最大值的下标索引，dim指明沿着哪个维度，keepdim表示是否保持维度。

			- print(torch.__version__)

				- 查看Torch的版本

			- print(torch.cuda.is_available())

				- 验证cuda是否安装成功

			- print(torch.version.cuda)

				- 查看Torch中对应的cuda版本

	- 分类

		- 全连接神经网络(FCNN)

			- 概念

				- 除输入层之外的每个节点都和上一层的所有节点相连。
				- 第N-1层的输出就是第N层的输入。

		- 卷积神经网络(CNN)

			- 结构

				- 输入层
				- 隐藏层

					- 卷积层(convolutional layer)

						- 卷积操作

						- 三种卷积模式

							- full mode

								- filter(卷积核)的右下边角与image的左上边角重合时开始卷积。
							- same mode

								- filter(卷积核)的中心与image的左上边角重合时开始卷积。
								- 这种模式下，如果步长stride为1，那么卷积前后图片大小不变。

							- valid mode

								- 整个filter(卷积核)与image的左上角重合时开始卷积。
						- PyTorch中的填充padding

							- 不填充: padding=0
							- 上下左右同时填充: padding=2
							- 上下填充: padding=(2, 0)
							- 左右填充: padding=(0, 2)

						- 感受野

							- 概念

								- 感受野指的是一个特定的CNN特征（特征图上的某个点）在输入空间所受影响的区域。
								- 一个感受野可以用中心位置(center location)和大小(size)来表征。
								- 对于一个CNN特征来说，感受野中的每个像素值（pixel）并不是同等重要。一个像素点越接近感受野中心，它对输出特征的计算所起作用越大。

							- 计算公式

								- 下面两个公式(化简后)是一样的，公式不难推导。
易知：每增加一个特征点，感受野(相对上一个特征图)增加s。
然后，比较相邻两个特征图的感受野的关系，即可得到计算公式。
						- 空洞卷积

							- 标准卷积

							- 空洞卷积

								- 扩大感受野
								- 捕获多尺度上下文信息

						- 卷积尺寸、卷积参数量、卷积计算量

							- 卷积尺寸计算公式

									- 推导过程

										- 1、Lout = (Lin-kernelsize)/stride+1
										- 2、考虑padding，Lin_new=Lin+2*padding
										- 3、考虑空洞，kernelsize_new=dilation(kernelsize-1)+1
										- 4、PyTorch默认卷积模式是valid，所以向下取整。

								- dilation=空洞数+1，即dilation=1表示没有空洞数。

							- 卷积参数量

							- 卷积计算量(浮点运算量)

								- 考虑偏置bias

								- 不考虑偏置bias

					- 池化层(pooling layer)

						- 池化是一种形式的下采样。池化层的引入是仿照人的视觉系统对视觉输入对象进行降维和抽象。

						- 两种常用的池化方法

							- 最大池化(max-pooling)

								- 取局部接受域中值最大的点。相当于高通滤波，倾向于保留图像的纹理信息。

							- 均值池化(mean-pooling)

								- 取局部接受域中的所有值的求均值。相当于低通滤波，倾向于保留图像的背景信息。

						- 功效

							- 1.特征不变性

								- 这种不变性包括平移(translation)、旋转(rotation)和缩放(scale)。
								- 使模型更加关注是否存在某些特征而不是特征的具体位置。
								- 即微小的位置变化具有鲁棒性。

							- 2.特征降维

								- 下采样(降采样)操作，降维压缩，减少计算量和参数量。

							- 3.在一定程度上防止过拟合

						- 自适应池化(丢弃很多特征，现在一般都不采用)

								-     # 1.不同的图片，经过自适应池化后得到相同的图片大小
    x1 = torch.randn(1, 64, 10, 9)  # NCHW
    x2 = torch.randn(1, 32, 20, 15)  # NCHW
    conv = nn.AdaptiveMaxPool2d((5, 7))
    y1 = conv(x1)
    y2 = conv(x2)
    print(y1.shape, y2.shape)

    print("------")

    # 2.定义不同的自适应池化
    x = torch.randn(1, 64, 10, 9)  # NCHW
    conv1 = nn.AdaptiveMaxPool2d((5, 7))  # H变为5，W变为7
    conv2 = nn.AdaptiveMaxPool2d(7)  # H和W都变为7
    conv3 = nn.AdaptiveMaxPool2d((None, 7))  # H不变，W变为7
    y1 = conv1(x)
    y2 = conv2(x)
    y3 = conv3(x)
    print(y1.shape, y2.shape, y3.shape)

					- 全连接层(fully-connected layer)

						- 整合特征

				- 输出层

			- 用途

				- 卷积神经网络（CNN）最重要的用途就是图像识别分类。对于图像识别来说，卷积神经网络通过尽可能保留重要的参数，去掉大量不重要的参数，来达到更好的学习效果。

	- 项目实战

		- 分类

			- 1、手写数字识别(项目)

				- 框架

					- PyTorch

				- 网络结构

					- 1）全连接神经网络

						- accuracy0.979

					- 2）卷积神经网络

						- accuracy0.9925

				- 项目流程

					- 1、准备图片数据
					- 2、自定义Dataset数据集
					- 3、自定义神经网络模型
					- 4、模型训练、验证(计算Accuracy)

			- 2、猫狗识别(项目)

				- 框架

					- PyTorch

				- 网络结构

					- 1）全连接神经网络

						- accuracy0.63

					- 2）卷积神经网络

						- accuracy0.75

				- 项目流程

					- 1、准备图片数据
					- 2、自定义Dataset数据集
					- 3、自定义神经网络模型
					- 4、模型训练、验证(计算Accuracy)

		- 回归

			- 1、小黄人单目标检测(项目)

				- 框架

					- PyTorch

				- 网络结构

					- 卷积神经网络

						- 4层卷积+1层全连接

							- 最高iou 0.86

						- 5层卷积+1层全连接

							- 最高iou 0.923

						- 6层卷积+1层全连接

							- 最高iou 0.9707

				- 项目流程

					- 1、准备小黄人图片
					- 2、使用爬虫技术从网上下载背景图片

						- python中的urllib库使用

							- 1.创建Request请求对象

								-     request = urllib.request.Request(self, url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)
    参数:
    url: 请求路径
    data: 请求体中的数据(PUT或POST请求)
    headers: 请求头
    method: 请求方法，如HEAD、GET、POST、DELETE等

							- 2.(模拟浏览器)发送请求，得到响应Response

								-     response = urllib.request.urlopen(request)
    print(response.read().decode('utf-8'))

							- 3.检索url数据到本地磁盘上

								-     urllib.request.urlretrieve(url, filename=None, reporthook=None, data=None)
    参数:
    url: url地址
    filename: 本地的文件路径

							- 4.中文汉字编码、解码

								-     keyword = "美丽的风景"
    # 编码: 中文转为utf-8
    keyword = urllib.parse.quote(keyword, "utf-8")
    # 解码: 将utf-8转回中文
    keyword = urllib.parse.unquote(keyword, "utf-8")

							- 5.python中的re模块

								-     从string中搜索所有匹配正则表达式的字符串，并返回list。
    1）方式1: re.findall(pattern, string, flags=0)
        image_urls = re.findall(r"thumbURL.*?\.jpg", str, re.S)
    2）方式2: pattern = re.compile(pattern, flags=0)、pattern.findall(string)
        p = re.compile(r"thumbURL.*?\.jpg", re.S)
        image_urls = p.findall(html)

    特殊字符:
    .   匹配除换行符 \n 之外的任何单字符。要匹配 . ，请使用 \. 。
    *   匹配前面的子表达式零次或多次。要匹配 * 字符，请使用 \*。
    +   匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 \+。
    ?   匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用 \?。

							- 6.python中str.format()的用法

								-     url = "https://image.baidu.com?queryWord={word}&ie=utf-8&word={word}&pn={pageNum}"
    url_new = url.format(word="liyunfei", pageNum="2")
    print(url_new)

							- 7.python中的os模块创建目录: os.path.exists(path)、os.makedirs(path)

								-     path = "Q:/cnn_target_detection/bg_pic"
    if not os.path.exists(path):
        print("目录不存在，创建该目录!")
        os.makedirs(path)
    else:
        print("目录已经存在!")

							- 8.python内置open(file, mode='r')函数，打开一个文件并返回文件对象

								-     # mode='a'表示打开一个文件用于追加，文件指针将会放在文件的结尾。
    with open("testpic.txt", mode="a") as f:
        ...
        # 关闭文件
        f.close()

							- 9.请求头headers类型

								- User-Agent: 浏览器类型
								- Referer: 包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。

					- 3、手动生成样本图片(将小黄人图片paste到背景图上)
					- 4、自定义神经网络模型(CNN)
					- 5、模型训练、验证(计算IOU)

		- 多类别多目标检测(分类+回归)

			- 1、人脸识别(项目)

				- 项目流程

					- 1）人脸侦测

						- 网络结构

							- MTCNN(Multi-task Cascaded Convolutional Networks，多任务级联卷积神经网络)

								- 训练

									- 1) Face classification(人脸分类)

									- 2) Bounding box regression(边界框回归)

									- 3) Facial landmark localization(关键点定位)

									- 4) Multi-source training

											- α表示每个任务在当前阶段网络的损失中所占的比重；
											- β也是采样类型指示，取值为{0,1}。当人脸/非人脸判定为人脸时，所有β=1；判定为非人脸时，box和landmark的β=0，而det的β=1。
											- 在这种情况下，我们很自然的使用SGD来训练CNN网络。

									- 5) Online Hard sample mining

										- 在每个小批中，我们对所有样本在正向传播中计算的损失进行排序，并选择其中最顶端的70%作为硬样本。然后我们只计算这些硬样本在反向传播中的梯度。这意味着在训练过程中，我们会忽略那些对增强检测器帮助不大的简单样本。实验表明，该策略在不需要人工选择样本的情况下，具有更好的性能。

								- 总体框架

										- P-Net(Proposal Network)

											- 利用一个浅层的CNN快速产生候选窗口。

										- R-Net(Refine Network)

											- 利用一个更复杂的CNN排除掉大量非人脸窗口。

										- O-Net(Output Network)

											- 利用一个更强大的CNN进一步改善结果，并输出人脸关键点位置。

									- 给定一幅图像，我们首先将其大小调整到不同的尺度，构建一个图像金字塔，作为三级级联框架的输入:

										- 阶段一：利用一个叫做Proposal network (P-Net)的全卷积网络，获取候选人脸窗口及其边界盒回归向量。然后根据估计的边界盒回归向量对候选对象进行校正(IOU置信度筛选)。在此之后，我们使用非最大抑制(NMS)来合并高度重叠的候选对象。
										- 阶段二：将所有候选窗口输入到另一个CNN，即Refine Network (R-Net)，该CNN进一步剔除大量的错误候选窗口，利用边界盒回归进行校正(IOU置信度筛选)，并进行NMS。
										- 阶段三：与阶段二类似，但在这一阶段，我们的目标是识别更多的监督面部区域。特别地，该网络将输出五个面部关键点位置。

								- CNN架构

									- 1）减少滤波器数量，并将5×5滤波器改为3×3滤波器以减少计算量；同时深度的增加可以获得更好的性能。
									- 2）使用PReLU作为卷积层和全连接层(不包括输出层)后的非线性激活函数。

					- 2）特征提取
					- 3）特征对比

