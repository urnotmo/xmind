# 行为识别

## 1.什么是行为识别？研究现状和未来展望？

### 1）什么是行为识别？

- 摘要

	- 人的行为识别是计算机视觉领域中的重点研究问题之一．
	- 相对于静态图像中物体识别研究，行为识别更加关注如何感知感兴趣目标在图像序列中的时空运动变化．
	- 视觉行为的存在方式从二维空间 到三维时空的扩展大大增加了行为表达及后续识别任务的复杂性，同时也为视觉研究者提供了更广阔 的空间以尝试不同的解决思路和技术方法．
	- 计算机视觉技术是研究怎样让计算机通过摄像机去获取外界的视觉信息，然后像人类一样知 道“看”到的是什么，并且理解“看”到的东西在哪里、 在“干”什么．因而，物体识别、目标跟踪和行为识别 是计算机视觉研究的重要问题．

- 分类(从简单到复杂)

	- 姿态
	- 单人行为
	- 交互行为
	- 群行为

- 数据库发展史

	- 1.早期的行为数据库（如KTH和WEIZANN 等）主要的出发点集中在对一些基本行为识别上．
	- 2.随着研究的深入，为解决视角不变问题，一些研究机构发布了多视角的行为数据，如IXMAS Actions数据库、CASIA行为数据库；通过利用多个视角信息的互补性来提高行为的表达能力.
	- 3.但在真实生活的视频里，行为类别是非常丰 富的，并且影响行为在视频中表达的因素也非常多， 如视角、光照，摄像机运动、环境变化等．对此，网络及多媒体视频由于其更为自然真实，并且具有海量、多样、易获取等特点，成为行为识别数据库的又一重要来源．基于此，在2008年和2009年，有很多真实场景下的行为数据库被发布，如 Hollywood，UFC Sports，UFC YouTube等。
	- 4.除网络多媒体视频外，还有一些研究者通过模 仿真实场景（考虑复杂的运动背景）构建了诸如MSR Action和Collective Activity Data等行为数据库．由于局部特征对于视角和光照等变化具有很好的鲁棒性，基于局部特征点的行为识别方法在这类真实场景数据库中得到广泛的应用．
	- 5.2010年以来，各种行为识别数据库百花齐放：

		- 2009年，随着"大数据"的来临，计算机视觉领域出现了以ImageNet图像库为代表的超大规模数据库。
		- 包含101个行为类别的UCF101行为数据库。
		- 包含51个行为类别的HMDB行为数据库。
		- IXMAS Actions数据库的种类增加：13类-->17类。
		- 行为识别从简单的单人行为上升到了多人的交互行为。如2010年发布 的监控场景下的 UT-Interaction数据库，其研究内容是多个目标之间的交互行为。
		- 另外，借助传感技 术的发展，MSR先后发布了MSR Action 3D和MSR Daily Activity 3D行为数据库，这２个数据库利用Kinect RGB-D传感器获取除彩色图像以外的人体深度图像序列，利用Kinect采集的深度数据可获取较为精准的人体关节点骨架序列，这些包含深度和骨架结构的视频序列为深入研究人体的运动模式提供了很好的研究数据.
		- 美国西北大学和加州 大学洛杉矶分校则将深度、骨架和多视角数据融合在一 起构建了Northwestern-UCLA Multiview Action 3D数据库．
		- 为了更好地研究人体运动过程中各个关节点的运动规律，CMU Graphics Lab利用８个红外摄像头对带有41个标记点的人体进 行重构，更为精确地估计出人体的骨架结构，并发布 了CMU Motion Capture行为数据库．
		- 除此之外， 随着穿戴式智能设备(如Google Glass)的发展，近几年来也出现了一些第1人称视角的行为数据库，如Activities of Daily Living (ADL) Dataset和First-Person Social Interactions数据库。

- 行为识别方法分类

	- 1.大数据真实场景下的行为识别
	- 2.基于深度图像序列的行为识别
	- 3.基于骨架序列 的行为识别
	- 4.基于第１人称视角的行为识别
	- 5.多人交互行为识别

## 2.行为识别算法综述

### 常用的公开数据集

### 动作识别根据动作特征模态来分类，主要有：

- 图像人体轮廓特征
-  深度图
- 视频人体运动光流
- 人体骨架

### 人体行为识别中的挑战：

- １）空间复杂性：不同光照、视角和背景等条件下会呈现不同的动作场景，而在不同的动作场景中相同的人体行为在姿态和特性上会产生差异。
- 2）时间差异性： 指人体动作发生的时间点不可预测，而且动作的持续间隔也不尽相同。 

### 行为识别步骤：

- 行为识别流程图：

- 典型的行为识别主要分3步进行：
- 1）人体目标检测

	- 从静态图中分割出人体前景，从包含动作信息的视频中分割出动作序列。
	- 从而得到容量更小，但包含足够运动信息的数据，并以数学形式的符号表达出人体动作。
	- 应用图像分割技术。
	- 人体动作行为识别越来越注重识别的实时性，动作序列的分割是未来运动目标检测的研究方向。

- 2）动作/行为表示

	- 动作表示也被称为特征提取，是视频行为识别的核心，动作表征选取的效果对人体动作行为识别有重要影响。
	- 有效的动作表示应该满足：

		- 1）判别性。即来自同一类别的行为表示带有类似的信息，来自不同类别的行为表示带有区别的信息。
		- 2）高效性。即行为表示易于计算和实现。
		- 3）低纬度。即意味着低成本的分类和识别。

- 3）动作识别

	- 最后，在动作表示提取的基础上，在空间序列和时间序列领域完成动作特征识别。
	- 动作特征识别可看成一个结合先验知识对数学符号进行训练和分类的过程。

### 识别方法分类

- 按照特征提取划分的方式：分为 基于传统手工特征的行为识别 和 基于深度特征的行为识别。

- 1）传统行为识别基本思想：通过一个图像对运动相关信息进行编码，通过在时空中的剪影引起的三维形状来表示动作。

	- 典型：DT算法、iDT算法(improved dense trajectories)。

- 2）基于深度特征的行为识别

	- 优势

		- 满足更高精度、更高速度的要求。
		- 利用深度学习模型去自动提取数据中的特征，避免了人工设计特征过程中的盲目性和差异性。
		- 深度学习模型通过端到端的神经网络结构进行深度特征提取和动作分类。 

	- Donahue提出的一种行为识别方法(CNN+LSTM)：

		- 1.将预处理的深度图像数据先送入原先设计好的CNN中获取空间特征。
		- 2.然后将视频数据中的光流信息送入LSTM中获取时序特征。
		- 3.融合空序特征和时序特征，并采用Soft-max映射类别。

	- 行为识别的两大类思路：

		- 1）以抽取并分类时空特征为目的的视频识别方法。
		- 2））以提取骨架信息进行再训练为目的的姿态估计方法。

	- 模型按照网络架构分类(3种)：

		- 综述

		- 1）双流方法(Two-Stream结构)

			- 网络架构

				- 两个分支，分别捕捉视频的空间和时间信息，然后融合结果去除过拟合。

					- 1）空域利用RGB图像作为输入提取外观特征；
					- 2）时域利用光流信息作为输入提取时序特征；

							- a，b是两个连续的帧图；
							- c为密集光流或光流位移场(矢量构成)；
							- d是光流位移场的水平分量，e是光流位移场的垂直分量；

						- 时域网络的输入(由多个连续视频间的光流位移场形成的光流信息)配置：

							- 1）光流堆叠：多个帧的相同位置的光流堆叠。

							- 2）轨迹堆叠：沿着光流的运动轨迹进行堆叠。

							- 3）双向光流
							- 4）平均流减法

					- 3）特征融合的两种优化方式：

						- Temporal Segment LSTM和Temporal-ConvNet。
			- 原理/步骤

				- 1）首先，对视频序列中每两帧计算密集光流，得到密集光流的序列(Temporal信息)。
				- 2）然后，对视频图像(Spatial)和密集光流(Temporal)分别训练CNN模型，两个分支的网络分别对动作的类别进行判断。
				- 3）最后，融合两个网络的训练结果，得到最终的分类结果。

			- 后期的一些网络优化：

				- 1）时域分割网络(TSN)

					- 视频进行时域分割后随机抽取片段。

						- 弥补只能处理短期动作，对长期动作时间结构理解不足的问题。

					- 用交叉预练、正则化技术和数据扩张技术。

						- 弥补训练样本较小的问题。

				- 2）时空残差网络模型

					- 通过空域流和时域流的残差连接分层地学习了行为的时空特征。

			- 优缺点：精度高，但速度慢。

		- 2）3D-ConvNet方法

			- 对视频中每一帧运用CNN来识别，这种方法并没有考虑到连续帧间的运动信息，仅能捕获到帧内的空间信息。3D卷积的方法，可以有效地综合运动信息。
			- 网络架构

			- 原理

				- 通过在CNNs的卷积层进行3D卷积，捕捉在时间和空间维度都具有区分性的特征。
				- 3D卷积是通过堆叠多个连续的帧组成的一个立方体，然后在立方体中运用3D卷积核。
				- 在这个结构中，卷积层中每一个特征图都会与上一层中多个邻近的连续帧相连，因此捕捉运动信息。

			- 步骤

				- 对2D卷积的扩展，添加了时间维度。
				- 1）首先，采用3D卷积核在输入视频的3D空间上进行采样，提取视频的时空特征。
				- 2）然后，利用SVM分类器进行分类。

			- 后期的一些网络优化：

				- 引入ResNet残差，Inception模块。
				- 1）T3D

					- 提出时域3D卷积核，并新增了时域变换层TTL(Temporal 3D-ConvNets)来替换池化层——以捕捉长时视频高层语义信息。

						- 弥补对长时域信息没有充分挖掘的问题。

			- 优缺点：速度快，精度比Two-Stream低。

				- 用Nvidia 1080显卡可以达到600fps以上，所以3D-ConvNet的效率远远高于其他方法，这使得3D-ConvNet有着很好的应用前景。

		- 3）融合方法(CNN-LSTM)

			- 融合CNN-LSTM网络的重点在于提取视频数据中的时空信息。
			- 原理

				- 1）首先，用CNN提取视频中的空间特征；
				- 2）利用循环神经网络LSTM提取视频中的时序信息。

			- 步骤

				- 不同于Two-Stream结构和3D-ConvNet结构，CNN-LSTM的结构输入数据模态一般为骨架序列。
				- 1）首先，通过RGB图像进行关节点估计或利用深度摄像机获取人体骨架序列，每一帧对应人体关节的坐标位置信息，一个时间序列由若干帧组成。
				- 2）然后用CNN-LSTM网络对构建出的骨架时序图提取高层特征；最后用Softmax分类器进行分类。

			- 后期的一些网络优化：

				- 时空融合的几种方式：

					- 1）晚融合(Late Fusion)
					- 2）早融合(Early Fusion)
					- 3）慢融合(Slow Fusion)

						- 效果最好

				- 1）LRCN

					- 将CNN与LSTM相结合来提取视频数据中的时空信息。
					- 为什么这样做？

						- 对视频进行分析处理的关键在于对时序特征的学习和理解。

				- 2）时空图卷积网络模型

					- 一个基于图的动态骨骼建模方法。是首个以完成行为识别的基于图形的神经网络应用。
					- 步骤：

						- 1.首先，通过"图卷积"提取骨架的空间特征；
						- 2.然后，通过时间卷积获取时序特征。
						- 3.最后，融合特征，得出试验结果。

				- 3）SR-TSL

					- 为了解决什么问题？

						- 现有的方法利用LSTM网络直接对整个骨架进行建模，利用最后一时刻的隐藏状态作为时序特征，但是对于长时序序列，最后一时刻的状态很难表示整个序列的时序特征。

					- 利用残差图神经网络对骨骼进行建模；然后将骨架序列进行等长分割送入LSTM中进行训练。

			- 优缺点：精度较高、算法较快。

## 3.人体姿态估计算法

### 参考资料

- https://blog.csdn.net/qq_38109843/article/details/102396365

- https://blog.csdn.net/weixin_41809530/article/details/107644477

### 2D

- 姿态估计的2种思路

	- 1）Top-Down(自上而下)：将人体检测和关键点检测分离。

		- 步骤

			- 1.在图像上首先进行人体检测，找到所有的人体框；
			- 2.对每个人体框再使用关键点检测。

		- 特点

			- 往往比较慢，但姿态估计准确率较高。

		- 目前主流的主要有：CPM，Hourglass，CMU OpenPose，AlphaPose。

	- 2）Bottom-Up(自下而上)

		- 步骤

			- 1.先检测图像中人体部件;
			- 2.然后，将图像中多人人体的部件分别组合成人体。

		- 特点

			- 往往更快速，准确率稍低。
			- 1）(优点)计算量不会因为图片上人物的增加而显著增加，能保证时间基本不变。
			- 2）(缺点)当人群密集，或者两个人靠的太近，就容易检测错误。

		- 典型就是COCO2016年人体关键点检测冠军Open Pose。

### 3D

- DensePose

	- 论文：https://arxiv.org/abs/1802.00434
github：https://github.com/facebookresearch/Densepose
配置：https://blog.csdn.net/FatMigo/article/details/88246815
论文解读：https://blog.csdn.net/Julia_deeplearning/article/details/83011798

- VideoPose3D

	- 论文：https://arxiv.org/abs/1811.11742
github：https://github.com/facebookresearch/VideoPose3D、https://github.com/tobiascz/VideoPose3D
论文解读：https://blog.csdn.net/chizhaoyi1901/article/details/89136182

### 常用的姿态估计算法概述

- 1）OpenPose

	- 源码

		- https://github.com/CMU-Perceptual-Computing-Lab/openpose

		- C++实现

	- 原始OpenPose对硬件要求较高。
	- 轻量级OpenPose——Lightweight OpenPose(基于mobileNetV2)

		- 源码

			- https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch

			- Python实现

		- 可以在CPU上运行，而且速度非常的快，但是准确性就比较差。
		- 能够在移动设备上运行，算是一个比较好的选择。

- 2）AlphaPose

	- 官方源码：AlphaPose-Pytorch：https://github.com/MVIG-SJTU/AlphaPose/tree/pytorch
	- Alphapose是自上而下的算法，也就是先检测倒人体，再得到关键点和骨架。

- AlphaPose与OpenPose对比

	- 1）AlphaPose准确率和AP值比OpenPose高。
	- 2）AlphaPose对于被遮挡部分的关键点不会任意获取，可以只显示看得到的部分。
	- 3）随着图片上的人数增加，AlphaPose的计算量大、速度慢。

- 3）Mobilepose

	- 轻量级网络来识别人体关键点，而且大部分都是单人姿态估计。

## 7.FFmpeg

### 资料

- 官网

	- http://www.ffmpeg.org/

- 安装包下载

	- https://github.com/BtbN/FFmpeg-Builds/releases

### 安装

- 1）下载安装包并解压(注意解压路径中不能有中文)。

- 2）将bin目录配置到环境变量中。

- 3）测试是否安装成功。

	- 控制台输入命令：ffmpeg，如图所示说明安装成功。

### 简单命令

- 1.视频不同类型之间的转换

	- ffmpeg -i input.avi output.mp4

- 2.视频转图片

	- ffmpeg -i "./video/1.webm" -threads 1 -vf scale=-1:256 -q:v 0 "./frames/1/%06d.jpg"

## 6.模型选型

### 时间分割网络——TSN(Temporal Segment Networks)

- 资料

	- 论文

		- https://arxiv.org/pdf/1608.00859.pdf

	- github

		- https://github.com/yjxiong/temporal-segment-networks

	- 参考资料

		- https://blog.csdn.net/zhang_can/article/details/79618781

		- https://blog.csdn.net/u010579901/article/details/80264496

- 主要思想

	- 深度卷积网络在静态图像的视觉识别方面取得了巨大的成功。然而，对于视频中的动作识别，相对于传统方法的优势并不明显。
	- 在有限的训练样本下，探索设计有效的卷积网络结构用于视频动作识别。
	- 设计时间分割网络TSN

		- 1.基于长时结构建模型的思想，结合稀疏时间采样策略和视频级监控，

- 是Two-Stream的升级版：

	- 1）时序的稀疏采样代替密集采样。

		- 弥补对长时域信息没有充分挖掘的问题。

	- 2）除了常用的数据增样、正则化技术、Drop外，还使用交叉预训练模式。

		- 在数据过少的情况下防止过拟合。

### TSM(Temporal Shift Module)

- 资料

	- github

		- https://github.com/mit-han-lab/temporal-shift-module

### Non-local Neural Networks

### 选用STM的原因？

- 1.视频识别的高效性、实时性是非常重要的。
- 2.2D-CNN比较高效，但是无法提取时域信息，识别精度低。
- 3.3D-CNN可以同时提取空域和时域信息，但计算量大，无法在边缘设备部署。
- 4.TSM(Temporal Shift Module)利用2D的复杂度实现3D的效果，不增加参数量和计算量，可以保证在边缘设备上部署。

## 4.数据集

### 常用数据集

- 1.FineGym数据集

	- 资料

		- 知乎贴：https://zhuanlan.zhihu.com/p/130720627
论文：https://arxiv.org/abs/2004.06704
数据集下载：https://sdolivia.github.io/FineGym/

	- 数据集结构("三加二")

		- 在语义层面，FineGym定义了三层的语义类别结构，遵循着从粗粒度到细粒度的顺序，它们包括：事件类别(event)、组类别（set）、元素类别(element)。
		- 在时域上，FineGym具有两层的结构，分别为动作和子动作。

	- 特点

		- 一个大规模、高质量、层级化标注的细粒度人体动作数据集。
		- 1.高质量
		- 2.丰富性与多样性
		- 3.完全以人体动作为中心
		- 4.决策树标注过程带来了比动作标签本身更丰富的信息

	- 应用场景

		- 动作识别任务、时域动作检测、动作质量评估、动作生成、动作属性识别等。

- 时间关联性较弱

	- 2.UCF101

		- 来源为YouTube视频，共计101类动作，13320段视频。共有5个大类的动作：1)人-物交互；2)肢体运动；3)人-人交互；4)弹奏乐器；5)运动。

	- 4.Kinetics
	- 3.HMDB51

		- 来源为YouTube视频，共计51类动作，约7000段视频。

- 时间关联性强

	- 5.Something-Something(V1&V2)
	- 6.Jester

### 暴力数据集

- 1.Hockey数据集

	- 来自国家冰球联盟比赛，包含了不同角度的人打架视频。

- 2.Crowd Violence数据集

	- 在YouTube上从真实的人群场景中收集。数据有140个视频分辨率为320*240像素，包含了123个暴力视频和123个非暴力视频。

### 常用数据标注工具

- 1.Labelme
- 2.LabelImg
- 3.OpenCV/CVAT
- 4.LabelHub
- 5.VoTT

## 5.光流(optical flow)

## 8.项目实战

